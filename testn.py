import os
import json
import torch
import torchaudio
from tqdm import tqdm
from pathlib import Path
from omegaconf import OmegaConf
from torch.utils.data import DataLoader, Dataset
from concurrent.futures import ThreadPoolExecutor, as_completed

from models.model import ChatStyleScorer
from datasets.collate import collate_style_batch

# ä¸‰ä¸ªé˜ˆå€¼ï¼ˆç»„/éŸ³é¢‘ä¸¤ä¸ªç»´åº¦éƒ½ä½¿ç”¨ï¼‰
THRESHOLDS = [0.67, 0.68, 0.69]


class InferenceDataset(Dataset):
    def __init__(self, data, target_sr=16000):
        self.data = data
        self.target_sr = target_sr

    def __getitem__(self, idx):
        sample = self.data[idx]
        wav_path = sample["wav_path"]
        utt_id = sample["utt_id"]

        waveform, sr = torchaudio.load(wav_path)
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0)
        else:
            waveform = waveform[0]
        if sr != self.target_sr:
            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.target_sr)(waveform)

        return {"waveform": waveform, "utt_id": utt_id}

    def __len__(self):
        return len(self.data)


def infer_one_dir(model, cfg, device, subdir: Path, output_name: str):
    """å¯¹ä¸€ä¸ªç›®å½•æ¨ç†ï¼Œè¾“å‡º jsonlï¼šç¬¬ä¸€è¡Œavgï¼Œåç»­å€’åºæ ·æœ¬ã€‚"""
    wav_files = sorted(subdir.glob("*.wav"))
    if not wav_files:
        return f"âš ï¸ è·³è¿‡ {subdir}ï¼šæ— éŸ³é¢‘", None

    data = [{"wav_path": str(wav), "utt_id": wav.stem} for wav in wav_files]
    dataset = InferenceDataset(data, cfg.dataset.target_sr)
    loader = DataLoader(dataset, batch_size=cfg.eval.batch_size, collate_fn=collate_style_batch)

    rows, scores = [], []
    with torch.no_grad():
        for batch in loader:
            wave = batch["waveforms"].to(device)
            mask = batch["attention_mask"].to(device)
            utt_ids = batch["utt_ids"]

            logits = model(wave, attention_mask=mask, inference_only=True)
            probs = torch.sigmoid(logits).cpu().tolist()

            for utt_id, score in zip(utt_ids, probs):
                s = float(round(score, 5))
                rows.append({"utt_id": utt_id, "score": s})
                scores.append(s)

    # æ’åº
    rows.sort(key=lambda x: x["score"], reverse=True)
    avg = round(sum(scores) / len(scores), 5) if scores else 0.0

    # å†™æ–‡ä»¶
    out_path = subdir / output_name
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(json.dumps({"avg": avg}, ensure_ascii=False) + "\n")
        for item in rows:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    return f"âœ… {subdir.name} å®Œæˆï¼šavg={avg}ï¼Œä¿å­˜åˆ°ï¼š{out_path}", {
        "dir": subdir.name,
        "count": len(scores),
        "avg": avg,
        "output_jsonl": str(out_path)
    }


def run_inference_multithread(cfg_path, ckpt_path, root_dir, output_name="chatScore.jsonl", max_workers=4):
    cfg = OmegaConf.load(cfg_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åŠ è½½æ¨¡å‹
    model = ChatStyleScorer(cfg).to(device)
    ckpt = torch.load(ckpt_path, map_location=device)
    model.load_state_dict(ckpt["model"])
    model.eval()

    print(f"\nğŸ§µ ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘æ¨ç†ï¼Œæœ€å¤§çº¿ç¨‹æ•°ï¼š{max_workers}")

    root_path = Path(root_dir)
    subdirs = [d for d in root_path.iterdir() if d.is_dir()]

    # å•ç›®å½•æ¨¡å¼
    single_dir_mode = False
    if not subdirs:
        wav_files = list(root_path.glob("*.wav"))
        if wav_files:
            subdirs = [root_path]
            single_dir_mode = True
        else:
            print(f"âš ï¸ è·³è¿‡ {root_path}ï¼šæ— éŸ³é¢‘æ–‡ä»¶")
            return

    metrics_list = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(infer_one_dir, model, cfg, device, subdir, output_name): subdir.name
            for subdir in subdirs
        }

        for future in tqdm(as_completed(futures), total=len(futures), desc="ğŸ“Š å­ç›®å½•æ¨ç†ä¸­"):
            subdir_name = futures[future]
            try:
                msg, metrics = future.result()
                print(msg)
                if metrics:
                    metrics_list.append(metrics)
            except Exception as e:
                print(f"âŒ å­ç›®å½• {subdir_name} å‡ºé”™ï¼š{e}")

    # åªæœ‰å¤šç›®å½•æ—¶æ‰å†™ global.json
    if metrics_list and not single_dir_mode:
        results_dir = root_path / "results"
        results_dir.mkdir(parents=True, exist_ok=True)

        total_count = sum(m["count"] for m in metrics_list)
        weighted_avg = round(sum(m["avg"] * m["count"] for m in metrics_list) / total_count, 5)

        avgs = [m["avg"] for m in metrics_list]
        avg_of_avgs = round(sum(avgs) / len(avgs), 5) if avgs else None
        max_dir_avg = max(avgs) if avgs else None
        min_dir_avg = min(avgs) if avgs else None
        dirs_ge_07 = sum(1 for a in avgs if a >= 0.7)
        dirs_ge_07_ratio = round(dirs_ge_07 / len(avgs), 5) if avgs else 0.0

        # === å…¨å±€è¯»å–å„ç›®å½• chatScore.jsonlï¼Œåšåˆ†å¸ƒ + å¤±è´¥ç»Ÿè®¡ ===
        all_scores = []
        # ç»„å¤±è´¥è®¡æ•°åˆå§‹åŒ–
        failed_group_counts = {"lt_0.67": 0, "lt_0.68": 0, "lt_0.69": 0}
        total_groups = len(metrics_list)
        # éŸ³é¢‘å¤±è´¥è®¡æ•°åˆå§‹åŒ–
        failed_audio_counts = {"lt_0.67": 0, "lt_0.68": 0, "lt_0.69": 0}
        total_audios = 0

        for m in metrics_list:
            group_has_lt = {0.67: False, 0.68: False, 0.69: False}
            with open(m["output_jsonl"], "r", encoding="utf-8") as f:
                # è·³è¿‡ç¬¬ä¸€è¡Œ avg
                first = f.readline()
                for line in f:
                    d = json.loads(line)
                    s = d["score"]
                    all_scores.append(s)
                    total_audios += 1
                    # éŸ³é¢‘ç»´åº¦å¤±è´¥è®¡æ•°
                    if s < 0.67:
                        failed_audio_counts["lt_0.67"] += 1
                        group_has_lt[0.67] = True
                    if s < 0.68:
                        failed_audio_counts["lt_0.68"] += 1
                        group_has_lt[0.68] = True
                    if s < 0.69:
                        failed_audio_counts["lt_0.69"] += 1
                        group_has_lt[0.69] = True

            # ç»„ç»´åº¦ï¼šä»»ä¸€ä½äºé˜ˆå€¼åˆ™è¯¥ç»„è®¡æ•°+1
            if group_has_lt[0.67]:
                failed_group_counts["lt_0.67"] += 1
            if group_has_lt[0.68]:
                failed_group_counts["lt_0.68"] += 1
            if group_has_lt[0.69]:
                failed_group_counts["lt_0.69"] += 1

        # å…¨å±€åˆ†å¸ƒç»Ÿè®¡ï¼ˆä¿æŒä½ åŸæœ‰çš„å››ä¸ªæ¡¶ï¼‰
        dist = {"lt_0.6": 0, "0.6-0.7": 0, "0.7-0.8": 0, "ge_0.8": 0}
        for s in all_scores:
            if s < 0.6:
                dist["lt_0.6"] += 1
            elif s < 0.7:
                dist["0.6-0.7"] += 1
            elif s < 0.8:
                dist["0.7-0.8"] += 1
            else:
                dist["ge_0.8"] += 1
        for k in dist:
            dist[k] = {
                "count": dist[k],
                "ratio": round(dist[k] / len(all_scores), 5) if all_scores else 0.0
            }

        # å¤±è´¥ç‡
        group_failure_rate = {
            k: round((failed_group_counts[k] / total_groups), 5) if total_groups else 0.0
            for k in failed_group_counts
        }
        audio_failure_rate = {
            k: round((failed_audio_counts[k] / total_audios), 5) if total_audios else 0.0
            for k in failed_audio_counts
        }

        global_info = {
            "root": str(root_path),
            "total_count": total_count,
            "weighted_avg": weighted_avg,
            "avg_of_avgs": avg_of_avgs,
            "max_dir_avg": max_dir_avg,
            "min_dir_avg": min_dir_avg,
            "dirs_ge_0.7_ratio": dirs_ge_07_ratio,
            "score_distribution": dist,

            # === æ–°å¢ï¼šç»„ç»´åº¦å¤±è´¥ç»Ÿè®¡ ===
            "total_groups": total_groups,
            "failed_group_counts": failed_group_counts,
            "group_failure_rate": group_failure_rate,

            # === æ–°å¢ï¼šéŸ³é¢‘ç»´åº¦å¤±è´¥ç»Ÿè®¡ ===
            "total_audios": total_audios,
            "failed_audio_counts": failed_audio_counts,
            "audio_failure_rate": audio_failure_rate
        }

        summary_path = results_dir / "global.json"
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump(global_info, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“¦ å…¨å±€æ±‡æ€»å®Œæˆï¼š{summary_path}")
    elif single_dir_mode:
        print("â„¹ï¸ å•ç›®å½•æ¨¡å¼ï¼šä»…ç”Ÿæˆè¯¥ç›®å½•çš„ jsonlï¼Œä¸ç”Ÿæˆ results/global.json")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, required=True)
    parser.add_argument("--ckpt", type=str, required=True)
    parser.add_argument("--root-dir", type=str, required=True)
    parser.add_argument("--output-name", type=str, default="chatScore.jsonl")
    parser.add_argument("--max-workers", type=int, default=4, help="æœ€å¤§çº¿ç¨‹æ•°")
    args = parser.parse_args()

    run_inference_multithread(
        args.config,
        args.ckpt,
        args.root_dir,
        output_name=args.output_name,
        max_workers=args.max_workers,
    )